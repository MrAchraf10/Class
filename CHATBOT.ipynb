{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6658a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "\n",
    "# Importer X_train\n",
    "with open('X_train.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "\n",
    "# Importer X_test\n",
    "with open('X_test.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "\n",
    "# Importer Y_train\n",
    "with open('Y_train.pkl', 'rb') as file:\n",
    "    Y_train = pickle.load(file)\n",
    "\n",
    "# Importer Y_test\n",
    "with open('Y_test.pkl', 'rb') as file:\n",
    "    Y_test = pickle.load(file)\n",
    "\n",
    "# Importer Y_combined\n",
    "with open('Y_combined.pkl', 'rb') as file:\n",
    "    Y_combined = pickle.load(file)\n",
    "\n",
    "# Importer Y_combined_encoded\n",
    "with open('Y_combined_encoded.pkl', 'rb') as file:\n",
    "    Y_combined_encoded = pickle.load(file)\n",
    "\n",
    "# Importer le\n",
    "with open('le.pkl', 'rb') as file:\n",
    "    le = pickle.load(file)\n",
    "\n",
    "# Importer Y_train_encoded\n",
    "with open('Y_train_encoded.pkl', 'rb') as file:\n",
    "    Y_train_encoded = pickle.load(file)\n",
    "\n",
    "# Importer Y_test_encoded\n",
    "with open('Y_test_encoded.pkl', 'rb') as file:\n",
    "    Y_test_encoded = pickle.load(file)\n",
    "\n",
    "# Importer Y_train_categorical\n",
    "with open('Y_train_categorical.pkl', 'rb') as file:\n",
    "    Y_train_categorical = pickle.load(file)\n",
    "\n",
    "# Importer Y_test_categorical\n",
    "with open('Y_test_categorical.pkl', 'rb') as file:\n",
    "    Y_test_categorical = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5c4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.pkl', 'rb') as file:\n",
    "    corpus = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9ebb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125180"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c651b705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remis', 'état', 'rénov', 'toitur', 'magasin', 'bureau', 'gantour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3dfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from gensim.models import Word2Vec\n",
    "from text_processor import TextProcessor\n",
    "from wordcloud_generator import WordCloudGenerator\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "max_len = 50\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8d6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.pkl', 'rb') as file:\n",
    "    classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a21727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input_text):\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        with open('classes.pkl', 'rb') as file:\n",
    "            classes = pickle.load(file)\n",
    "        \n",
    "        # load trained model\n",
    "        model = load_model('LSTM_Mdel.py')\n",
    "        \n",
    "        model_w2v = Word2Vec.load(\"model_w2v.bin\")\n",
    "        \n",
    "        # Importer le\n",
    "        with open('le.pkl', 'rb') as file:\n",
    "            le = pickle.load(file)\n",
    "            \n",
    "        with open('corpus.pkl', 'rb') as file:\n",
    "            corpus = pickle.load(file)\n",
    "        \n",
    "        if input_text.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        # Create an instance of TextProcessor\n",
    "        text_processor = TextProcessor()\n",
    "\n",
    "        # Preprocess the new text\n",
    "        preprocessed_text = text_processor.process(input_text)\n",
    "\n",
    "        # Check if the input text is readable\n",
    "        if any(char.isalpha() for char in input_text):\n",
    "\n",
    "            # Check if the input text contains only one word\n",
    "            if len(preprocessed_text) == 1:\n",
    "                response = \"Please add more details to your input.\"\n",
    "            else:\n",
    "                # Convert the preprocessed text into word embeddings\n",
    "                new_text_vec = []\n",
    "                for word in preprocessed_text:\n",
    "                    if word in model_w2v.wv:\n",
    "                        new_text_vec.append(model_w2v.wv[word])\n",
    "                    else:\n",
    "                        new_text_vec.append(np.zeros(embedding_size))\n",
    "                new_text_vec = np.array([new_text_vec])\n",
    "\n",
    "                # Pad the embedded sequence\n",
    "                padded_new_text_vec = pad_sequences(new_text_vec, max_len)\n",
    "                predictions = model.predict(padded_new_text_vec)\n",
    "                predicted_class_index = np.argmax(predictions[0])\n",
    "                predicted_class = le.inverse_transform([predicted_class_index])[0]\n",
    "                predicted_class_str = str(predicted_class)\n",
    "                return predicted_class_str\n",
    "        \n",
    "        else:\n",
    "            response = \"Please enter a readable text.\"\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d919c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "User: Entrer le titre du projet: rechargement galet sécheur\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "ChatBot: Le code SF correspondant : 22503\n",
      "User: Entrer le titre du projet: rechargement usinage galet sécheur\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "ChatBot: Le code SF correspondant : 22503\n",
      "User: Entrer le titre du projet: rechargement usinage galet four sécheur\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "ChatBot: Le code SF correspondant : 51515\n",
      "User: Entrer le titre du projet: réepreuve et extincteurs\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000191970AFAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "ChatBot: Le code SF correspondant : 51601\n",
      "User: Entrer le titre du projet: réepreuve et recharge extincteurs\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019194499E10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "ChatBot: Le code SF correspondant : 22503\n",
      "User: Entrer le titre du projet: quit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
