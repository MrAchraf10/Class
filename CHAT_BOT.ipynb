{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b9ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Importer X_train\n",
    "with open('X_train.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "\n",
    "# Importer X_test\n",
    "with open('X_test.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "\n",
    "# Importer Y_train\n",
    "with open('Y_train.pkl', 'rb') as file:\n",
    "    Y_train = pickle.load(file)\n",
    "\n",
    "# Importer Y_test\n",
    "with open('Y_test.pkl', 'rb') as file:\n",
    "    Y_test = pickle.load(file)\n",
    "\n",
    "# Importer Y_combined\n",
    "with open('Y_combined.pkl', 'rb') as file:\n",
    "    Y_combined = pickle.load(file)\n",
    "\n",
    "# Importer Y_combined_encoded\n",
    "with open('Y_combined_encoded.pkl', 'rb') as file:\n",
    "    Y_combined_encoded = pickle.load(file)\n",
    "\n",
    "# Importer le\n",
    "with open('le.pkl', 'rb') as file:\n",
    "    le = pickle.load(file)\n",
    "\n",
    "# Importer Y_train_encoded\n",
    "with open('Y_train_encoded.pkl', 'rb') as file:\n",
    "    Y_train_encoded = pickle.load(file)\n",
    "\n",
    "# Importer Y_test_encoded\n",
    "with open('Y_test_encoded.pkl', 'rb') as file:\n",
    "    Y_test_encoded = pickle.load(file)\n",
    "\n",
    "# Importer Y_train_categorical\n",
    "with open('Y_train_categorical.pkl', 'rb') as file:\n",
    "    Y_train_categorical = pickle.load(file)\n",
    "\n",
    "# Importer Y_test_categorical\n",
    "with open('Y_test_categorical.pkl', 'rb') as file:\n",
    "    Y_test_categorical = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d94ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.pkl', 'rb') as file:\n",
    "    corpus = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60eef3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d050a022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remis', 'état', 'rénov', 'toitur', 'magasin', 'bureau', 'gantour']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f991ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from gensim.models import Word2Vec\n",
    "from text_processor import TextProcessor\n",
    "from wordcloud_generator import WordCloudGenerator\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "max_len = 50\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3099a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.pkl', 'rb') as file:\n",
    "    classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18ddc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        with open('classes.pkl', 'rb') as file:\n",
    "            classes = pickle.load(file)\n",
    "        \n",
    "        # load trained model\n",
    "        model = load_model('New_Model.py')\n",
    "        \n",
    "        model_w2v = Word2Vec.load(\"model_w2v.bin\")\n",
    "        \n",
    "        # Importer le\n",
    "        with open('le.pkl', 'rb') as file:\n",
    "            le = pickle.load(file)\n",
    "            \n",
    "        with open('corpus.pkl', 'rb') as file:\n",
    "            corpus = pickle.load(file)\n",
    "        \n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        input_text = input(\"Entrer le titre du projet: \")\n",
    "        \n",
    "        if input_text.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        # Create an instance of TextProcessor\n",
    "        text_processor = TextProcessor()\n",
    "\n",
    "        # Preprocess the new text\n",
    "        preprocessed_text = text_processor.process(input_text)\n",
    "        \n",
    "        # Convert the preprocessed text into word embeddings\n",
    "        new_text_vec = []\n",
    "        for word in preprocessed_text:\n",
    "            if word in model_w2v.wv:\n",
    "                new_text_vec.append(model_w2v.wv[word])\n",
    "            else:\n",
    "                new_text_vec.append(np.zeros(embedding_size))\n",
    "        new_text_vec = np.array([new_text_vec])\n",
    "\n",
    "        # Pad the embedded sequence\n",
    "        padded_new_text_vec = pad_sequences(new_text_vec, max_len)\n",
    "        predictions = model.predict(padded_new_text_vec)\n",
    "        predicted_class_index = np.argmax(predictions[0])\n",
    "        predicted_class = le.inverse_transform([predicted_class_index])[0]\n",
    "        predicted_class_str = str(predicted_class)\n",
    "        classes_str = classes.astype(str)\n",
    "        if predicted_class_str in classes_str :\n",
    "            print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , \"Le code SF correspondant :\", predicted_class_str)\n",
    "        else :\n",
    "            print(\"Je suis désolé, je n'ai pas pu trouver le code SF correspondant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baaf4765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "User: Entrer le titre du projet: déchets médicaux\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "ChatBot: Le code SF correspondant : 22305\n",
      "User: Entrer le titre du projet: quit\n"
     ]
    }
   ],
   "source": [
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be89845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'22305'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('New_Model.py')\n",
    "\n",
    "model_w2v = Word2Vec.load(\"model_w2v.bin\")\n",
    "\n",
    "text_processor = TextProcessor()\n",
    "\n",
    "input_text = \"Déchets médicaux\"\n",
    "\n",
    "# Preprocess the new text\n",
    "preprocessed_text = text_processor.process(input_text)\n",
    "        \n",
    "# Convert the preprocessed text into word embeddings\n",
    "new_text_vec = []\n",
    "for word in preprocessed_text:\n",
    "    if word in model_w2v.wv:\n",
    "        new_text_vec.append(model_w2v.wv[word])\n",
    "    else:\n",
    "        new_text_vec.append(np.zeros(embedding_size))\n",
    "new_text_vec = np.array([new_text_vec])\n",
    "\n",
    "# Pad the embedded sequence\n",
    "padded_new_text_vec = pad_sequences(new_text_vec, max_len)\n",
    "predictions = model.predict(padded_new_text_vec)\n",
    "predicted_class_index = np.argmax(predictions[0])\n",
    "predicted_class = le.inverse_transform([predicted_class_index])[0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2542c6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U5')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
